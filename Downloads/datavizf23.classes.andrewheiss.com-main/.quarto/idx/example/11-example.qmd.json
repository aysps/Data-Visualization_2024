{"title":"Time","markdown":{"yaml":{"title":"Time","date":"2023-10-30","date_end":"2023-11-03"},"headingText":"Live coding example","containsRefs":false,"markdown":"\n\n```{r load-targets, include=FALSE}\nwithr::with_dir(here::here(), {\n  fred_path <- targets::tar_read(data_fred)\n})\n```\n\nFor this example, we're going to use economic data from the US Federal Reserve (the Fed). The St. Louis Fed is in charge of publishing Fed economic data, and they host it all at an online portal named [FRED](https://fred.stlouisfed.org/). Instead of downloading individual time series data from the FRED website, we'll do what with did with the World Bank WDI data and download it directly from the internet with the [{tidyquant} package](https://business-science.github.io/tidyquant/), which includes a function for working with the FRED API/website.\n\nIf you want to skip the data downloading, you can download the data below (you'll likely need to right click and choose \"Save Link As…\"):\n\n- [{{< fa file-csv >}} `fred_raw.csv`](/`r fred_path`)\n\n\n\n<div class=\"ratio ratio-16x9\">\n<iframe src=\"https://www.youtube.com/embed/ObnRqO4zTY8\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\"></iframe>\n</div>\n\n\n::: {.callout-important}\n### Slight differences from the video\n\nThis is a slightly cleaned up version of the code from the video.\n:::\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(fig.width = 6, fig.height = 3.6, fig.align = \"center\", collapse = TRUE)\nset.seed(1234)\noptions(\"digits\" = 2, \"width\" = 150)\n```\n\n## Get data\n\nFirst, we load the libraries we'll be using:\n\n```{r load-libraries, message=FALSE, warning=FALSE}\nlibrary(tidyverse)  # For ggplot, dplyr, and friends\nlibrary(tidyquant)  # For accessing FRED data\nlibrary(scales)     # For nicer labels\n```\n\nThe US Federal Reserve provides thousands of economic datasets at [FRED](https://fred.stlouisfed.org/). We can use the [{tidyquant} R package](https://business-science.github.io/tidyquant/) to access their servers and download the data directly into R.\n\nLike we did with the [WDI indicators in session 8](/example/08-example.qmd), we need to find the special internal code for the variables we want to get. We need to pay close attention to the details of each variable, since the same measure can be offered with different combinations of real (adjusted for inflation) or nominal (not adjusted for inflation); monthly, quarterly, or annually; and seasonally adjusted or not seasonally adjusted. For instance, if you want to see US GDP, here are some possibilities (all the possible GDP measures are [listed here](https://fred.stlouisfed.org/categories/106)):\n\n- [`GDPC1`: Real (2012 dollars), quarterly, seasonally adjusted](https://fred.stlouisfed.org/series/GDPC1)\n- [`ND000334Q`: Real (2012 dollars), quarterly, not seasonally adjusted](https://fred.stlouisfed.org/series/ND000334Q)\n- [`GDPCA`: Real (2012 dollars), annual, not seasonally adjusted](https://fred.stlouisfed.org/series/GDPCA)\n- [`GDP`: Nominal, quarterly, seasonally adjusted](https://fred.stlouisfed.org/series/GDP)\n- [`GDPA`: Nominal, annual, not seasonally adjusted](https://fred.stlouisfed.org/series/GDPA)\n\nThe code for getting data from FRED works a little differently than `WDI()`, and the output is a little different too, but it's hopefully not too complicated. We need to feed the `tq_get()` function (1) a list of indicators we want, (2) a source for those indicators, and (3) a starting and/or ending date.\n\n`tq_get()` can actually get data from a ton of different sources like stocks from Yahoo Finance and general financial data from [Bloomberg](https://www.bloomberg.com/professional/solution/bloomberg-terminal), [Quandl](https://www.quandl.com/), and [Tiingo](https://api.tiingo.com/). Most of those other sources require a subscription and a fancy API key that logs you into their servers when getting data, but FRED is free (yay public goods!).\n\nWe'll first make a new dataset named `fred_raw` that gets a bunch of interesting variables from FRED from January 1, 1990 until today.\n\n```{r get-fred-data, eval=FALSE}\nfred_raw <- tq_get(c(\"RSXFSN\",  # Advance retail sales\n                     \"GDPC1\",  # GDP\n                     \"ICSA\",  # Initial unemployment claims\n                     \"FPCPITOTLZGUSA\",  # Inflation\n                     \"UNRATE\",  # Unemployment rate\n                     \"USREC\"),  # Recessions\n                   get = \"economic.data\",  # Use FRED\n                   from = \"1990-01-01\")\n```\n\nDownloading data from FRED every time you knit will get tedious and take a long time (plus if their servers are temporarily down, you won't be able to get the data). As with the World Bank data we used, it's good practice to save this raw data as a CSV file and then work with that.\n\nSince we care about reproducibility, we still want to include the code we used to get data from FRED, we just don't want it to actually run. You can include chunks but not run them by setting `eval=FALSE` in the chunk options. In this little example, we show the code for downloading the data, but we don't evaluate the chunk. We then include a chunk that loads the data from a CSV file with `read_csv()`, but we don't include it (`include=FALSE`). That way, in the knitted file we see the `WDI()` code, but in reality it's loading the data from CSV. Super tricky.\n\n````markdown\nI first download data from FRED:\n\n```{{r get-fred-data, eval=FALSE}}\nfred_raw <- tq_get(...)\n\nwrite_csv(fred_raw, \"data/fred_raw.csv\")\n```\n\n```{{r load-fred-data-real, include=FALSE}}\nfred_raw <- read_csv(\"data/fred_raw.csv\")\n```\n\n````\n\n```{r load-data-real, include=FALSE}\nfred_raw <- read_csv(here::here(fred_path))\n```\n\n## Look at and clean data\n\nThe data we get from FRED is in a slightly different format than we're used to with `WDI()`, but with good reason. With World Bank data, you get data for every country and every year, so there are rows for Afghanistan 2000, Afghanistan 2001, etc. You then get a column for each of the variables you want (population, life expectancy, GDP/capita, etc.)\n\nWith FRED data, that kind of format doesn't work for every possible time series variable because time is spaced differently. If you want to work with annual GDP, you should have a row for each year. If you want quarterly GDP, you should have a row for every quarter. If you put these in the same dataset, you'll end up with all sorts of missing data issues:\n\n| `time`   | `annual_gdp` | `quarterly_gdp` |\n| -------- | :----------: | :-------------: |\n| 2019, Q1 |      X       |        X        |\n| 2019, Q2 |              |        X        |\n| 2019, Q3 |              |        X        |\n| 2019, Q4 |              |        X        |\n| 2020, Q1 |      X       |        X        |\n| 2020, Q2 |              |        X        |\n\nTo fix this, the {tidyquant} package gives you data in tidy (or long) form and only provides three columns:\n\n```{r show_fred_head}\nhead(fred_raw)\n```\n\nThe `symbol` column is the ID of the variable from FRED , `date` is… the date, and `price` is the value. These columns are called symbol and price because the {tidyquant} package was designed to get and process stock data, so you'd typically see stock symbols (like AAPL or MSFT) and stock prices. When working with FRED data, the `price` column shows the value of whatever you're interested in—it's not technically a price (so unemployment claims, inflation rates, and GDP values are still called `price`).\n\nRight now, our `fred_raw` dataset has only 3 columns, but nearly 3,000 rows since the six indicators we got from the server are all stacked on top of each other. To actually work with these, we need to filter the raw data so that it only includes the indicators we're interested in. For instance, if we want to plot retail sales, we need to select only the rows where the symbol is `RSXFSN`. Make a smaller dataset with `filter()` to do that:\n\n```{r make-retail-sales}\nretail_sales <- fred_raw %>% \n  filter(symbol == \"RSXFSN\")\n\nretail_sales\n```\n\nIf multiple variables have the same spacing (annual, quarterly, monthly, weekly), you can use filter to select all of them and then the use `pivot_wider()` or `spread()` to make separate columns for each. Inflation, unemployment, and retail sales are all monthly, so we can make a dataset for just those:\n\n```{r make-monthly-things-1}\nfred_monthly_things <- fred_raw %>% \n  filter(symbol %in% c(\"FPCPITOTLZGUSA\", \"UNRATE\", \"RSXFSN\")) %>% \n  # Convert the symbol column into multiple columns, using the \"prices\" for values\n  pivot_wider(names_from = symbol, values_from = price)\n\nfred_monthly_things\n```\n\nBut wait! There's a problem! The inflation rate we got isn't actually monthly—it seems to be annual, which explains all the `NA`s. Let's fix it by not including it. We'll also rename the columns so they're easier to work with\n\n```{r make-monthly-things-2}\nfred_monthly_things <- fred_raw %>% \n  filter(symbol %in% c(\"UNRATE\", \"RSXFSN\")) %>% \n  # Convert the symbol column into multiple columns, using the \"prices\" for values\n  pivot_wider(names_from = symbol, values_from = price) %>% \n  rename(unemployment = UNRATE, retail_sales = RSXFSN)\n\nfred_monthly_things\n```\n\nAll better.\n\nWe can make as many subsets of the long, tidy, raw data as we want.\n\n\n## Plotting time\n\nLet's plot some of these and see what the trends look like. We'll just use `geom_line()`. \n\nHere's GDP:\n\n```{r gdp-basic}\n# Get just GDP data from the raw FRED data\ngdp_only <- fred_raw %>% \n  filter(symbol == \"GDPC1\")\n\nggplot(gdp_only, aes(x = date, y = price)) +\n  geom_line()\n```\n\nHere's retail sales:\n\n```{r retail-sales-basic}\n# Get just GDP data from the raw FRED data\nretail_sales_only <- fred_raw %>% \n  filter(symbol == \"RSXFSN\")\n\nggplot(retail_sales_only, aes(x = date, y = price)) +\n  geom_line()\n```\n\nAnd here's unemployment claims:\n\n```{r unemp-claims}\nunemployment_claims_only <- fred_raw %>% \n  filter(symbol == \"ICSA\")\n\nggplot(unemployment_claims_only, aes(x = date, y = price)) +\n  geom_line()\n```\n\nYikes COVID-19.\n\nThere, we visualized time. `r emoji::emoji(\"check\")`\n\n\n## Improving graphics\n\nThese were simple graphs and they're kind of helpful, but they're not incredibly informative. We can clean these up a little. First we can change the labels and themes and colors:\n\n```{r gdp-better}\nggplot(gdp_only, aes(x = date, y = price)) +\n  geom_line(color = \"#0074D9\", linewidth = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(y = \"Billions of 2012 dollars\",\n       x = NULL,\n       title = \"US Gross Domestic Product\",\n       subtitle = \"Quarterly data; real 2012 dollars\",\n       caption = \"Source: US Bureau of Economic Analysis and FRED\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nThat's great and almost good enough to publish! We can add one additional layer of information onto the plot and highlight when recessions start and end. We included a recessions variable (`USREC`) when we got data from FRED, so let's see what it looks like:\n\n```{r show-recessions}\nfred_raw %>% \n  filter(symbol == \"USREC\")\n```\n\nThis is monthly data that shows a 1 if we were in a recession that month and a 0 if we weren't. The Fed doesn't decide when recessions happen—the [National Bureau of Economic Research (NBER)](https://www.nber.org/) does, and they have [specific guidelines](https://en.wikipedia.org/wiki/Recession#Definition) for defining one. We're probably in one right now, but there's not enough data for NBER to formally declare it yet.\n\nThis data is long and tidy, but that makes it harder to work with given our GDP. We want the start and end dates for each recession so that we can shade those areas on the plot. To find those dates, we need to do a little data reshaping. First, we'll create a temporary variable that marks if there was a switch from 0 to 1 or 1 to 0 in a given row by looking at the previous row\n\n```{r get-recessions-change}\nrecessions_tidy <- fred_raw %>% \n  filter(symbol == \"USREC\") %>% \n  mutate(recession_change = price - lag(price))\nrecessions_tidy\n```\n\nNotice the new column we have that is mostly 0s, but 1 when there's a switch, like in August 1990. 1 means we went from 0 to 1 (no recession → recession), while -1 means we went from 1 to 0 (recession → no recession).\n\nWe can see all the start and end dates if we filter:\n\n```{r}\nrecessions_start_end <- fred_raw %>% \n  filter(symbol == \"USREC\") %>% \n  mutate(recession_change = price - lag(price)) %>% \n  filter(recession_change != 0)\nrecessions_start_end\n```\n\nFinally, we can use `tibble()` to create a brand new little dataset row that includes columns for the start and end dates of each recession. We'll use a combination of `filter()` and `pull()` to extract the start dates (where `recession_change` is 1) and the end dates (where `recession_change` is −1), and then we'll stick those two vectors together in a data frame.\n\nIf you're creating this tiny dataset during an actual recession, though, you need to do a little extra step. If you're currently in a recession, the `recession_ends` vector will be one element shorted than the `recession_starts` vector, since the ongoing recession hasn't ended yet. We can check for this with code. If the `recession_ends` vector is shorter than `recesison_starts`, will stick an end date to the recession as `today()` (`today()` by itself returns regular text like `\"2023-11-01\"`; we need to tell R that this is a date by feeding it to `ymd()`)\n\n```{r make-recessions-official}\n# Pull out the start dates\nrecession_starts <- recessions_start_end %>% \n  filter(recession_change == 1) %>% \n  pull(date)\nrecession_starts\n\n# Pull out the end dates\nrecession_ends <- recessions_start_end %>% \n  filter(recession_change == -1) %>% \n  pull(date)\nrecession_ends\n\n# Check the length of `recession_ends` and append `today()` if it doesn't \n# match `recession_starts`\n#\n# If you're running this code not during a recession, there's no need for this\n# intermediate step, but it's good practice to include it just in case you run\n# this code in the future and you *are* in a recession\nif (length(recession_ends) < length(recession_starts)) {\n  recession_ends <- c(recession_ends, ymd(today()))\n}\n\n# Make a dataframe with the two vectors of start and end dates\nrecessions <- tibble(start = recession_starts,\n                     end = recession_ends)\nrecessions\n```\n\nWe can now add this tiny dataset to our plot using `geom_rect()`. Notice how we put `geom_rect()` *before* `geom_line()`—that's so the recession rectangles go under the line instead of on top of it. Also notice that we have to specify 4 new aesthetics for `geom_rect()`: min and max values for both x and y. We use the recession start and end dates for `xmin` and `xmax`, and then use −∞ and ∞ for `ymin` and `ymax` to make the rectangles stretch from the bottom of the plot to the top.\n\nThe last odd/new thing here is that we also use `inherit.aes = FALSE` in `geom_rect()`. That's because we specified a global `x` and `y` aesthetic in `ggplot()`, which applies to all the other layers we add. `geom_rect()` doesn't use `x` or `y`, though, and it'll complain that those columns are missing. The `inherit.aes` argument tells ggplot that the `geom_rect()` layer should not get any of the global aesthetics like `x` or `y`.\n\n```{r gdp-fancy-awesom}\nggplot(gdp_only, aes(x = date, y = price)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line(color = \"#0074D9\", linewidth = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(y = \"Billions of 2012 dollars\",\n       x = NULL,\n       title = \"US Gross Domestic Product\",\n       subtitle = \"Quarterly data; real 2012 dollars\",\n       caption = \"Source: US Bureau of Economic Analysis and FRED\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nAnd that's it!\n\nNow that we have the tiny recessions data frame, we can add it to any plot we want. Here's initial unemployment claims with some extra annotations for fun:\n\n```{r unemployment-fancy}\nggplot(unemployment_claims_only, aes(x = date, y = price)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line(color = \"#FF4136\", linewidth = 0.5) +\n  annotate(geom = \"label\", x = as.Date(\"2010-01-01\"), y = 1000000, \n           label = \"The Great Recession\", size = 3, family = \"Roboto Condensed\") +\n  annotate(geom = \"label\", x = as.Date(\"2020-01-01\"), y = 6000000, \n           label = \"COVID-19\", size = 3, family = \"Roboto Condensed\", hjust = 1) +\n  scale_y_continuous(labels = label_comma()) +\n  labs(y = \"Initial unemployment claims\",\n       x = NULL,\n       title = \"Initial unemployment claims\",\n       subtitle = \"Weekly data\",\n       caption = \"Source: US Employment and Training Administration and FRED\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\n## Decomposition\n\nThe mechanics of decomposing and forecasting time series goes beyond the scope of this class, but there are lots of resources you can use to learn more, including [this phenomenal free textbook](https://otexts.com/fpp3/).\n\nThere's a whole ecosystem of time-related packages that make working with time and decomposing trends easy (named [{tidyverts}](https://tidyverts.org/)):\n\n- [{lubridate}](https://lubridate.tidyverse.org/): Helpful functions for manipulating dates (you've used this before)\n- [{tsibble}](https://tsibble.tidyverts.org/): Add fancy support for time variables to data frames\n- [{feasts}](https://feasts.tidyverts.org/): Decompose time series and do other statistical things with time\n- [{fable}](https://fable.tidyverts.org/): Make forecasts\n\nHere's a super short example of how these all work. \n\nThe retail sales data we got from FRED was not seasonally adjusted, so it looks like it has a heartbeat embedded in it:\n\n```{r retail-sales-full}\nretail_sales <- fred_raw %>% \n  filter(symbol == \"RSXFSN\")\n\nggplot(retail_sales, aes(x = date, y = price)) +\n  geom_line()\n```\n\nWe can divide this trend into its main components: the trend, the seasonality, and stuff that's not explained by either the trend or the seasonality. To do that, we need to first modify our little dataset and tell it to be a time-enabled data frame (a `tsibble`) that is indexed by the year+month for each row. We'll create a new column called `year_month` and then use `as_tsibble()` to tell R that this is really truly dealing with time:\n\n```{r convert-to-tsibble, warning=FALSE, message=FALSE}\nlibrary(tsibble)  # For embedding time things into data frames\n\nretail_sales <- fred_raw %>% \n  filter(symbol == \"RSXFSN\") %>% \n  mutate(year_month = yearmonth(date)) %>% \n  as_tsibble(index = year_month)\nretail_sales\n```\n\nNotice that the `year_month` column is now just the year+month. Neato.\n\nNext we need to create a time series model using that data. There are lots of different ways to model time series, and distinguishing between the different types is *way* beyond the scope of this class. [Rob Hyndman's free books covers them all](https://otexts.com/fpp3/). We'll do this with [STL decomposition](https://otexts.com/fpp2/stl.html) (\"**S**easonal and **T**rend decomposition using **L**oess\") There are other models we can use, like ETS or ARIMA, but again, that's all beyond this class.\n\n```{r build-model, warning=FALSE, message=FALSE}\nlibrary(feasts)  # For decomposition things like STL()\n\nretail_model <- retail_sales %>% \n  model(stl = STL(price))\nretail_model\n```\n\nThe decomposition model we create is kind of boring and useless—it's all stored in a single cell.\n\nWe can extract the different components of the decomposition with the `components()` function: \n\n```{r autoplot-basic}\nretail_components <- components(retail_model)\nretail_components\n```\n\nAnd we can use the `autoplot()` function from the {feasts} package to quickly plot all the components. The plot that `autoplot()` creates is made with ggplot, so any normal ggplot layers work with it:\n\n```{r auto-plot-theme}\nautoplot(retail_components) +\n  labs(x = NULL) +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nWe can also plot individual components on their own using the `retail_components` dataset we made. Here's seasonality by itself:\n\n```{r retail-season-only}\nggplot(retail_components, \n       aes(x = year_month, y = season_year)) +\n  geom_rect(data = recessions,\n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line() + \n  scale_y_continuous(labels = label_dollar()) +\n  # ggplot needs to know that the main data is a yearmonth column so that it'll\n  # deal with the recessions data correctly; without this, you'll get an error\n  scale_x_yearmonth() +\n  labs(x = NULL, y = \"Difference from trend, millions of dollars\",\n       title = \"Seasonal trends in retail sales\",\n       subtitle = \"Nominal US dollars\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nAnd here's the trend by itself:\n\n```{r retail-trend-only}\nggplot(retail_components, \n       aes(x = year_month, y = trend)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line() + \n  scale_y_continuous(labels = label_dollar()) +\n  scale_x_yearmonth() +\n  labs(x = NULL, y = \"Trend, millions of dollars\",\n       title = \"Seasonally adjusted trends in retail sales\",\n       subtitle = \"Nominal US dollars\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nIf you want more control over the combined decomposed plot you can either (1) make individual plots for each of the components and then stitch them together with [{patchwork}](https://patchwork.data-imaginist.com/), or (2) make the components dataset tidy and facet by component. Here's what that looks like: \n\n```{r tidy-components}\nretail_components_tidy <- retail_components %>% \n  # Get rid of this column\n  select(-season_adjust) %>% \n  # Take all these component columns and put them into a long column\n  pivot_longer(cols = c(price, trend, season_year, remainder),\n               names_to = \"component\", values_to = \"value\") %>% \n  # Recode this values so they're nicer\n  mutate(component = recode(component, \n                            price = \"Actual data\",\n                            trend = \"Trend\",\n                            season_year = \"Seasonality\",\n                            remainder = \"Remainder\")) %>% \n  # Make the component categories follow the order they're in in the data so\n  # that \"Actual data\" is first, etc.\n  mutate(component = fct_inorder(component))\n\nretail_components_tidy\n```\n\nNow that we have a long dataset, we can facet by component:\n\n```{r plot-seasonality-fancy, fig.width=7, fig.height=5}\nggplot(retail_components_tidy, \n       aes(x = year_month, y = value)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line() + \n  scale_y_continuous(labels = label_dollar()) +\n  scale_x_yearmonth() +\n  labs(x = NULL, y = \"Millions of dollars\",\n       title = \"Decomposed US Advance Retail Sales\",\n       subtitle = \"Nominal US dollars\",\n       caption = \"Source: US Census Bureau and FRED (RSXFSN)\") +\n  facet_wrap(vars(component), ncol = 1, scales = \"free_y\") +\n  theme_minimal(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"),\n        plot.title.position = \"plot\",\n        strip.text = element_text(face = \"bold\", hjust = 0))\n```\n\nBeautiful!\n","srcMarkdownNoYaml":"\n\n```{r load-targets, include=FALSE}\nwithr::with_dir(here::here(), {\n  fred_path <- targets::tar_read(data_fred)\n})\n```\n\nFor this example, we're going to use economic data from the US Federal Reserve (the Fed). The St. Louis Fed is in charge of publishing Fed economic data, and they host it all at an online portal named [FRED](https://fred.stlouisfed.org/). Instead of downloading individual time series data from the FRED website, we'll do what with did with the World Bank WDI data and download it directly from the internet with the [{tidyquant} package](https://business-science.github.io/tidyquant/), which includes a function for working with the FRED API/website.\n\nIf you want to skip the data downloading, you can download the data below (you'll likely need to right click and choose \"Save Link As…\"):\n\n- [{{< fa file-csv >}} `fred_raw.csv`](/`r fred_path`)\n\n\n## Live coding example\n\n<div class=\"ratio ratio-16x9\">\n<iframe src=\"https://www.youtube.com/embed/ObnRqO4zTY8\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" frameborder=\"0\"></iframe>\n</div>\n\n\n::: {.callout-important}\n### Slight differences from the video\n\nThis is a slightly cleaned up version of the code from the video.\n:::\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(fig.width = 6, fig.height = 3.6, fig.align = \"center\", collapse = TRUE)\nset.seed(1234)\noptions(\"digits\" = 2, \"width\" = 150)\n```\n\n## Get data\n\nFirst, we load the libraries we'll be using:\n\n```{r load-libraries, message=FALSE, warning=FALSE}\nlibrary(tidyverse)  # For ggplot, dplyr, and friends\nlibrary(tidyquant)  # For accessing FRED data\nlibrary(scales)     # For nicer labels\n```\n\nThe US Federal Reserve provides thousands of economic datasets at [FRED](https://fred.stlouisfed.org/). We can use the [{tidyquant} R package](https://business-science.github.io/tidyquant/) to access their servers and download the data directly into R.\n\nLike we did with the [WDI indicators in session 8](/example/08-example.qmd), we need to find the special internal code for the variables we want to get. We need to pay close attention to the details of each variable, since the same measure can be offered with different combinations of real (adjusted for inflation) or nominal (not adjusted for inflation); monthly, quarterly, or annually; and seasonally adjusted or not seasonally adjusted. For instance, if you want to see US GDP, here are some possibilities (all the possible GDP measures are [listed here](https://fred.stlouisfed.org/categories/106)):\n\n- [`GDPC1`: Real (2012 dollars), quarterly, seasonally adjusted](https://fred.stlouisfed.org/series/GDPC1)\n- [`ND000334Q`: Real (2012 dollars), quarterly, not seasonally adjusted](https://fred.stlouisfed.org/series/ND000334Q)\n- [`GDPCA`: Real (2012 dollars), annual, not seasonally adjusted](https://fred.stlouisfed.org/series/GDPCA)\n- [`GDP`: Nominal, quarterly, seasonally adjusted](https://fred.stlouisfed.org/series/GDP)\n- [`GDPA`: Nominal, annual, not seasonally adjusted](https://fred.stlouisfed.org/series/GDPA)\n\nThe code for getting data from FRED works a little differently than `WDI()`, and the output is a little different too, but it's hopefully not too complicated. We need to feed the `tq_get()` function (1) a list of indicators we want, (2) a source for those indicators, and (3) a starting and/or ending date.\n\n`tq_get()` can actually get data from a ton of different sources like stocks from Yahoo Finance and general financial data from [Bloomberg](https://www.bloomberg.com/professional/solution/bloomberg-terminal), [Quandl](https://www.quandl.com/), and [Tiingo](https://api.tiingo.com/). Most of those other sources require a subscription and a fancy API key that logs you into their servers when getting data, but FRED is free (yay public goods!).\n\nWe'll first make a new dataset named `fred_raw` that gets a bunch of interesting variables from FRED from January 1, 1990 until today.\n\n```{r get-fred-data, eval=FALSE}\nfred_raw <- tq_get(c(\"RSXFSN\",  # Advance retail sales\n                     \"GDPC1\",  # GDP\n                     \"ICSA\",  # Initial unemployment claims\n                     \"FPCPITOTLZGUSA\",  # Inflation\n                     \"UNRATE\",  # Unemployment rate\n                     \"USREC\"),  # Recessions\n                   get = \"economic.data\",  # Use FRED\n                   from = \"1990-01-01\")\n```\n\nDownloading data from FRED every time you knit will get tedious and take a long time (plus if their servers are temporarily down, you won't be able to get the data). As with the World Bank data we used, it's good practice to save this raw data as a CSV file and then work with that.\n\nSince we care about reproducibility, we still want to include the code we used to get data from FRED, we just don't want it to actually run. You can include chunks but not run them by setting `eval=FALSE` in the chunk options. In this little example, we show the code for downloading the data, but we don't evaluate the chunk. We then include a chunk that loads the data from a CSV file with `read_csv()`, but we don't include it (`include=FALSE`). That way, in the knitted file we see the `WDI()` code, but in reality it's loading the data from CSV. Super tricky.\n\n````markdown\nI first download data from FRED:\n\n```{{r get-fred-data, eval=FALSE}}\nfred_raw <- tq_get(...)\n\nwrite_csv(fred_raw, \"data/fred_raw.csv\")\n```\n\n```{{r load-fred-data-real, include=FALSE}}\nfred_raw <- read_csv(\"data/fred_raw.csv\")\n```\n\n````\n\n```{r load-data-real, include=FALSE}\nfred_raw <- read_csv(here::here(fred_path))\n```\n\n## Look at and clean data\n\nThe data we get from FRED is in a slightly different format than we're used to with `WDI()`, but with good reason. With World Bank data, you get data for every country and every year, so there are rows for Afghanistan 2000, Afghanistan 2001, etc. You then get a column for each of the variables you want (population, life expectancy, GDP/capita, etc.)\n\nWith FRED data, that kind of format doesn't work for every possible time series variable because time is spaced differently. If you want to work with annual GDP, you should have a row for each year. If you want quarterly GDP, you should have a row for every quarter. If you put these in the same dataset, you'll end up with all sorts of missing data issues:\n\n| `time`   | `annual_gdp` | `quarterly_gdp` |\n| -------- | :----------: | :-------------: |\n| 2019, Q1 |      X       |        X        |\n| 2019, Q2 |              |        X        |\n| 2019, Q3 |              |        X        |\n| 2019, Q4 |              |        X        |\n| 2020, Q1 |      X       |        X        |\n| 2020, Q2 |              |        X        |\n\nTo fix this, the {tidyquant} package gives you data in tidy (or long) form and only provides three columns:\n\n```{r show_fred_head}\nhead(fred_raw)\n```\n\nThe `symbol` column is the ID of the variable from FRED , `date` is… the date, and `price` is the value. These columns are called symbol and price because the {tidyquant} package was designed to get and process stock data, so you'd typically see stock symbols (like AAPL or MSFT) and stock prices. When working with FRED data, the `price` column shows the value of whatever you're interested in—it's not technically a price (so unemployment claims, inflation rates, and GDP values are still called `price`).\n\nRight now, our `fred_raw` dataset has only 3 columns, but nearly 3,000 rows since the six indicators we got from the server are all stacked on top of each other. To actually work with these, we need to filter the raw data so that it only includes the indicators we're interested in. For instance, if we want to plot retail sales, we need to select only the rows where the symbol is `RSXFSN`. Make a smaller dataset with `filter()` to do that:\n\n```{r make-retail-sales}\nretail_sales <- fred_raw %>% \n  filter(symbol == \"RSXFSN\")\n\nretail_sales\n```\n\nIf multiple variables have the same spacing (annual, quarterly, monthly, weekly), you can use filter to select all of them and then the use `pivot_wider()` or `spread()` to make separate columns for each. Inflation, unemployment, and retail sales are all monthly, so we can make a dataset for just those:\n\n```{r make-monthly-things-1}\nfred_monthly_things <- fred_raw %>% \n  filter(symbol %in% c(\"FPCPITOTLZGUSA\", \"UNRATE\", \"RSXFSN\")) %>% \n  # Convert the symbol column into multiple columns, using the \"prices\" for values\n  pivot_wider(names_from = symbol, values_from = price)\n\nfred_monthly_things\n```\n\nBut wait! There's a problem! The inflation rate we got isn't actually monthly—it seems to be annual, which explains all the `NA`s. Let's fix it by not including it. We'll also rename the columns so they're easier to work with\n\n```{r make-monthly-things-2}\nfred_monthly_things <- fred_raw %>% \n  filter(symbol %in% c(\"UNRATE\", \"RSXFSN\")) %>% \n  # Convert the symbol column into multiple columns, using the \"prices\" for values\n  pivot_wider(names_from = symbol, values_from = price) %>% \n  rename(unemployment = UNRATE, retail_sales = RSXFSN)\n\nfred_monthly_things\n```\n\nAll better.\n\nWe can make as many subsets of the long, tidy, raw data as we want.\n\n\n## Plotting time\n\nLet's plot some of these and see what the trends look like. We'll just use `geom_line()`. \n\nHere's GDP:\n\n```{r gdp-basic}\n# Get just GDP data from the raw FRED data\ngdp_only <- fred_raw %>% \n  filter(symbol == \"GDPC1\")\n\nggplot(gdp_only, aes(x = date, y = price)) +\n  geom_line()\n```\n\nHere's retail sales:\n\n```{r retail-sales-basic}\n# Get just GDP data from the raw FRED data\nretail_sales_only <- fred_raw %>% \n  filter(symbol == \"RSXFSN\")\n\nggplot(retail_sales_only, aes(x = date, y = price)) +\n  geom_line()\n```\n\nAnd here's unemployment claims:\n\n```{r unemp-claims}\nunemployment_claims_only <- fred_raw %>% \n  filter(symbol == \"ICSA\")\n\nggplot(unemployment_claims_only, aes(x = date, y = price)) +\n  geom_line()\n```\n\nYikes COVID-19.\n\nThere, we visualized time. `r emoji::emoji(\"check\")`\n\n\n## Improving graphics\n\nThese were simple graphs and they're kind of helpful, but they're not incredibly informative. We can clean these up a little. First we can change the labels and themes and colors:\n\n```{r gdp-better}\nggplot(gdp_only, aes(x = date, y = price)) +\n  geom_line(color = \"#0074D9\", linewidth = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(y = \"Billions of 2012 dollars\",\n       x = NULL,\n       title = \"US Gross Domestic Product\",\n       subtitle = \"Quarterly data; real 2012 dollars\",\n       caption = \"Source: US Bureau of Economic Analysis and FRED\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nThat's great and almost good enough to publish! We can add one additional layer of information onto the plot and highlight when recessions start and end. We included a recessions variable (`USREC`) when we got data from FRED, so let's see what it looks like:\n\n```{r show-recessions}\nfred_raw %>% \n  filter(symbol == \"USREC\")\n```\n\nThis is monthly data that shows a 1 if we were in a recession that month and a 0 if we weren't. The Fed doesn't decide when recessions happen—the [National Bureau of Economic Research (NBER)](https://www.nber.org/) does, and they have [specific guidelines](https://en.wikipedia.org/wiki/Recession#Definition) for defining one. We're probably in one right now, but there's not enough data for NBER to formally declare it yet.\n\nThis data is long and tidy, but that makes it harder to work with given our GDP. We want the start and end dates for each recession so that we can shade those areas on the plot. To find those dates, we need to do a little data reshaping. First, we'll create a temporary variable that marks if there was a switch from 0 to 1 or 1 to 0 in a given row by looking at the previous row\n\n```{r get-recessions-change}\nrecessions_tidy <- fred_raw %>% \n  filter(symbol == \"USREC\") %>% \n  mutate(recession_change = price - lag(price))\nrecessions_tidy\n```\n\nNotice the new column we have that is mostly 0s, but 1 when there's a switch, like in August 1990. 1 means we went from 0 to 1 (no recession → recession), while -1 means we went from 1 to 0 (recession → no recession).\n\nWe can see all the start and end dates if we filter:\n\n```{r}\nrecessions_start_end <- fred_raw %>% \n  filter(symbol == \"USREC\") %>% \n  mutate(recession_change = price - lag(price)) %>% \n  filter(recession_change != 0)\nrecessions_start_end\n```\n\nFinally, we can use `tibble()` to create a brand new little dataset row that includes columns for the start and end dates of each recession. We'll use a combination of `filter()` and `pull()` to extract the start dates (where `recession_change` is 1) and the end dates (where `recession_change` is −1), and then we'll stick those two vectors together in a data frame.\n\nIf you're creating this tiny dataset during an actual recession, though, you need to do a little extra step. If you're currently in a recession, the `recession_ends` vector will be one element shorted than the `recession_starts` vector, since the ongoing recession hasn't ended yet. We can check for this with code. If the `recession_ends` vector is shorter than `recesison_starts`, will stick an end date to the recession as `today()` (`today()` by itself returns regular text like `\"2023-11-01\"`; we need to tell R that this is a date by feeding it to `ymd()`)\n\n```{r make-recessions-official}\n# Pull out the start dates\nrecession_starts <- recessions_start_end %>% \n  filter(recession_change == 1) %>% \n  pull(date)\nrecession_starts\n\n# Pull out the end dates\nrecession_ends <- recessions_start_end %>% \n  filter(recession_change == -1) %>% \n  pull(date)\nrecession_ends\n\n# Check the length of `recession_ends` and append `today()` if it doesn't \n# match `recession_starts`\n#\n# If you're running this code not during a recession, there's no need for this\n# intermediate step, but it's good practice to include it just in case you run\n# this code in the future and you *are* in a recession\nif (length(recession_ends) < length(recession_starts)) {\n  recession_ends <- c(recession_ends, ymd(today()))\n}\n\n# Make a dataframe with the two vectors of start and end dates\nrecessions <- tibble(start = recession_starts,\n                     end = recession_ends)\nrecessions\n```\n\nWe can now add this tiny dataset to our plot using `geom_rect()`. Notice how we put `geom_rect()` *before* `geom_line()`—that's so the recession rectangles go under the line instead of on top of it. Also notice that we have to specify 4 new aesthetics for `geom_rect()`: min and max values for both x and y. We use the recession start and end dates for `xmin` and `xmax`, and then use −∞ and ∞ for `ymin` and `ymax` to make the rectangles stretch from the bottom of the plot to the top.\n\nThe last odd/new thing here is that we also use `inherit.aes = FALSE` in `geom_rect()`. That's because we specified a global `x` and `y` aesthetic in `ggplot()`, which applies to all the other layers we add. `geom_rect()` doesn't use `x` or `y`, though, and it'll complain that those columns are missing. The `inherit.aes` argument tells ggplot that the `geom_rect()` layer should not get any of the global aesthetics like `x` or `y`.\n\n```{r gdp-fancy-awesom}\nggplot(gdp_only, aes(x = date, y = price)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line(color = \"#0074D9\", linewidth = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(y = \"Billions of 2012 dollars\",\n       x = NULL,\n       title = \"US Gross Domestic Product\",\n       subtitle = \"Quarterly data; real 2012 dollars\",\n       caption = \"Source: US Bureau of Economic Analysis and FRED\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nAnd that's it!\n\nNow that we have the tiny recessions data frame, we can add it to any plot we want. Here's initial unemployment claims with some extra annotations for fun:\n\n```{r unemployment-fancy}\nggplot(unemployment_claims_only, aes(x = date, y = price)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line(color = \"#FF4136\", linewidth = 0.5) +\n  annotate(geom = \"label\", x = as.Date(\"2010-01-01\"), y = 1000000, \n           label = \"The Great Recession\", size = 3, family = \"Roboto Condensed\") +\n  annotate(geom = \"label\", x = as.Date(\"2020-01-01\"), y = 6000000, \n           label = \"COVID-19\", size = 3, family = \"Roboto Condensed\", hjust = 1) +\n  scale_y_continuous(labels = label_comma()) +\n  labs(y = \"Initial unemployment claims\",\n       x = NULL,\n       title = \"Initial unemployment claims\",\n       subtitle = \"Weekly data\",\n       caption = \"Source: US Employment and Training Administration and FRED\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\n## Decomposition\n\nThe mechanics of decomposing and forecasting time series goes beyond the scope of this class, but there are lots of resources you can use to learn more, including [this phenomenal free textbook](https://otexts.com/fpp3/).\n\nThere's a whole ecosystem of time-related packages that make working with time and decomposing trends easy (named [{tidyverts}](https://tidyverts.org/)):\n\n- [{lubridate}](https://lubridate.tidyverse.org/): Helpful functions for manipulating dates (you've used this before)\n- [{tsibble}](https://tsibble.tidyverts.org/): Add fancy support for time variables to data frames\n- [{feasts}](https://feasts.tidyverts.org/): Decompose time series and do other statistical things with time\n- [{fable}](https://fable.tidyverts.org/): Make forecasts\n\nHere's a super short example of how these all work. \n\nThe retail sales data we got from FRED was not seasonally adjusted, so it looks like it has a heartbeat embedded in it:\n\n```{r retail-sales-full}\nretail_sales <- fred_raw %>% \n  filter(symbol == \"RSXFSN\")\n\nggplot(retail_sales, aes(x = date, y = price)) +\n  geom_line()\n```\n\nWe can divide this trend into its main components: the trend, the seasonality, and stuff that's not explained by either the trend or the seasonality. To do that, we need to first modify our little dataset and tell it to be a time-enabled data frame (a `tsibble`) that is indexed by the year+month for each row. We'll create a new column called `year_month` and then use `as_tsibble()` to tell R that this is really truly dealing with time:\n\n```{r convert-to-tsibble, warning=FALSE, message=FALSE}\nlibrary(tsibble)  # For embedding time things into data frames\n\nretail_sales <- fred_raw %>% \n  filter(symbol == \"RSXFSN\") %>% \n  mutate(year_month = yearmonth(date)) %>% \n  as_tsibble(index = year_month)\nretail_sales\n```\n\nNotice that the `year_month` column is now just the year+month. Neato.\n\nNext we need to create a time series model using that data. There are lots of different ways to model time series, and distinguishing between the different types is *way* beyond the scope of this class. [Rob Hyndman's free books covers them all](https://otexts.com/fpp3/). We'll do this with [STL decomposition](https://otexts.com/fpp2/stl.html) (\"**S**easonal and **T**rend decomposition using **L**oess\") There are other models we can use, like ETS or ARIMA, but again, that's all beyond this class.\n\n```{r build-model, warning=FALSE, message=FALSE}\nlibrary(feasts)  # For decomposition things like STL()\n\nretail_model <- retail_sales %>% \n  model(stl = STL(price))\nretail_model\n```\n\nThe decomposition model we create is kind of boring and useless—it's all stored in a single cell.\n\nWe can extract the different components of the decomposition with the `components()` function: \n\n```{r autoplot-basic}\nretail_components <- components(retail_model)\nretail_components\n```\n\nAnd we can use the `autoplot()` function from the {feasts} package to quickly plot all the components. The plot that `autoplot()` creates is made with ggplot, so any normal ggplot layers work with it:\n\n```{r auto-plot-theme}\nautoplot(retail_components) +\n  labs(x = NULL) +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nWe can also plot individual components on their own using the `retail_components` dataset we made. Here's seasonality by itself:\n\n```{r retail-season-only}\nggplot(retail_components, \n       aes(x = year_month, y = season_year)) +\n  geom_rect(data = recessions,\n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line() + \n  scale_y_continuous(labels = label_dollar()) +\n  # ggplot needs to know that the main data is a yearmonth column so that it'll\n  # deal with the recessions data correctly; without this, you'll get an error\n  scale_x_yearmonth() +\n  labs(x = NULL, y = \"Difference from trend, millions of dollars\",\n       title = \"Seasonal trends in retail sales\",\n       subtitle = \"Nominal US dollars\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nAnd here's the trend by itself:\n\n```{r retail-trend-only}\nggplot(retail_components, \n       aes(x = year_month, y = trend)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line() + \n  scale_y_continuous(labels = label_dollar()) +\n  scale_x_yearmonth() +\n  labs(x = NULL, y = \"Trend, millions of dollars\",\n       title = \"Seasonally adjusted trends in retail sales\",\n       subtitle = \"Nominal US dollars\") +\n  theme_bw(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"))\n```\n\nIf you want more control over the combined decomposed plot you can either (1) make individual plots for each of the components and then stitch them together with [{patchwork}](https://patchwork.data-imaginist.com/), or (2) make the components dataset tidy and facet by component. Here's what that looks like: \n\n```{r tidy-components}\nretail_components_tidy <- retail_components %>% \n  # Get rid of this column\n  select(-season_adjust) %>% \n  # Take all these component columns and put them into a long column\n  pivot_longer(cols = c(price, trend, season_year, remainder),\n               names_to = \"component\", values_to = \"value\") %>% \n  # Recode this values so they're nicer\n  mutate(component = recode(component, \n                            price = \"Actual data\",\n                            trend = \"Trend\",\n                            season_year = \"Seasonality\",\n                            remainder = \"Remainder\")) %>% \n  # Make the component categories follow the order they're in in the data so\n  # that \"Actual data\" is first, etc.\n  mutate(component = fct_inorder(component))\n\nretail_components_tidy\n```\n\nNow that we have a long dataset, we can facet by component:\n\n```{r plot-seasonality-fancy, fig.width=7, fig.height=5}\nggplot(retail_components_tidy, \n       aes(x = year_month, y = value)) +\n  geom_rect(data = recessions, \n            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),\n            inherit.aes = FALSE, fill = \"#B10DC9\", alpha = 0.3) +\n  geom_line() + \n  scale_y_continuous(labels = label_dollar()) +\n  scale_x_yearmonth() +\n  labs(x = NULL, y = \"Millions of dollars\",\n       title = \"Decomposed US Advance Retail Sales\",\n       subtitle = \"Nominal US dollars\",\n       caption = \"Source: US Census Bureau and FRED (RSXFSN)\") +\n  facet_wrap(vars(component), ncol = 1, scales = \"free_y\") +\n  theme_minimal(base_family = \"Roboto Condensed\") +\n  theme(plot.title = element_text(face = \"bold\"),\n        plot.title.position = \"plot\",\n        strip.text = element_text(face = \"bold\", hjust = 0))\n```\n\nBeautiful!\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"highlight-style":"monokai","toc-depth":4,"filters":["../filters/format_date_end.lua"],"output-file":"11-example.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["../files/bib/readings.bib"],"csl":"../files/bib/chicago-author-date.csl","_quarto-vars":{"author":"Andrew Heiss","instructor":{"name":"Dr. Andrew Heiss","name_no_title":"Andrew Heiss","email":"aheiss@gsu.edu","url":"https://www.andrewheiss.com","twitter":"andrewheiss","github":"andrewheiss","office":"55 Park Place SE, Room 464","contact_policy":"E-mail and Slack are the best ways to get in contact with me. I will try to respond to all course-related e-mails and Slack messages within 24 hours (*really*), but also remember that life can be busy and chaotic for everyone (including me!), so if I don't respond right away, don't worry!","appointment_url":"https://calendly.com/andrewheiss/"},"course":{"number":"PMAP 8551/4551","semester":"Fall 2023","days":"Any day","time":"Asynchronous","location":"Anywhere","dates":"August 12–December 11, 2023","github":"https://www.github.com/andrewheiss/datavizf23.classes.andrewheiss.com","url":"https://datavizf23.classes.andrewheiss.com","copyright_year":"2023","slack":"https://gsudatavizf2023.slack.com"},"university":{"name":"Georgia State University","url":"https://www.gsu.edu"},"school":{"name":"Andrew Young School of Policy Studies","url":"https://aysps.gsu.edu/"}},"theme":["litera","../html/custom.scss"],"date-heading":{"content":"Example for","class":"bg-example"},"date-format":"full","template-partials":["../html/title-block.html"],"title":"Time","date":"2023-10-30","date_end":"2023-11-03"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}